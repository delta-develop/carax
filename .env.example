# API authentication for protected endpoints (e.g. /author, /chat)
# Choose any non-empty value in development; clients must send it as a Bearer token.
API_KEY=dev-leonardo-key

# OpenAI configuration (required to generate responses in real runs)
# Get an API key from https://platform.openai.com/ and paste it below.
# Tests can run without a real key because they mock the LLM client.

OPENAI_API_KEY=sk-REPLACE_ME
OPENAI_MODEL=gpt-5
OPENAI_TEMPERATURE=1

# Another useful configuration for faster responses is:

# OPENAI_API_KEY=sk-REPLACE_ME
# OPENAI_MODEL=gpt-4o
# OPENAI_TEMPERATURE=0.7

# Redis configuration used for working/short-term memory
# Default in Docker Compose resolves to the service hostname "redis".
# You can override with a full URL if needed, e.g. redis://localhost:6379
REDIS_URL=redis://redis:6379

# PostgreSQL async connection string for SQLModel
# Defaults to the Compose service hostname "postgres" and DB name "db".
# Format: postgresql+asyncpg://<user>:<password>@<host>:<port>/<database>
DB_ASYNC_CONNECTION_STR=postgresql+asyncpg://carax:carax123@postgres:5432/conversations

# ngrok (optional) â€” used by the ngrok service in docker-compose.yml
# Obtain a token from https://dashboard.ngrok.com/get-started/your-authtoken
NGROK_AUTHTOKEN=REPLACE_ME

# Optional app tuning (not strictly used everywhere yet)
# Maximum number of recent messages to keep in memory per conversation
MAX_TURNS=10

# SonarQube local scan
SONAR_HOST_URL=http://localhost:9000
SONAR_TOKEN=<pon-tu-token-aqui>
